[2020-10-19 22:11:04,413] {taskinstance.py:670} INFO - Dependencies all met for <TaskInstance: tutorial.sqlite_to_df 2020-10-19T16:30:15.912664+00:00 [queued]>
[2020-10-19 22:11:04,419] {taskinstance.py:670} INFO - Dependencies all met for <TaskInstance: tutorial.sqlite_to_df 2020-10-19T16:30:15.912664+00:00 [queued]>
[2020-10-19 22:11:04,419] {taskinstance.py:880} INFO - 
--------------------------------------------------------------------------------
[2020-10-19 22:11:04,419] {taskinstance.py:881} INFO - Starting attempt 1 of 2
[2020-10-19 22:11:04,419] {taskinstance.py:882} INFO - 
--------------------------------------------------------------------------------
[2020-10-19 22:11:04,424] {taskinstance.py:901} INFO - Executing <Task(PythonOperator): sqlite_to_df> on 2020-10-19T16:30:15.912664+00:00
[2020-10-19 22:11:04,426] {standard_task_runner.py:54} INFO - Started process 16446 to run task
[2020-10-19 22:11:04,451] {standard_task_runner.py:77} INFO - Running: ['airflow', 'run', 'tutorial', 'sqlite_to_df', '2020-10-19T16:30:15.912664+00:00', '--job_id', '277', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/tutorial.py', '--cfg_path', '/var/folders/4j/yctg8njd19g2873bfk914jqw0000gn/T/tmpkbkkma4m']
[2020-10-19 22:11:04,453] {standard_task_runner.py:78} INFO - Job 277: Subtask sqlite_to_df
[2020-10-19 22:11:04,478] {logging_mixin.py:112} INFO - Running %s on host %s <TaskInstance: tutorial.sqlite_to_df 2020-10-19T16:30:15.912664+00:00 [running]> Arpitas-MacBook-Pro.local
[2020-10-19 22:11:04,493] {base_hook.py:89} INFO - Using connection to: id: sqlite_default. Host: /Users/arpitasaha/airflow/dags/db/B2BPlatform.db, Port: None, Schema: /Users/arpitasaha/airflow/dags/db/B2BPlatform.db, Login: None, Password: None, extra: None
[2020-10-19 22:11:04,494] {taskinstance.py:1150} ERROR - unable to open database file
Traceback (most recent call last):
  File "/Users/arpitasaha/opt/anaconda3/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 984, in _run_raw_task
    result = task_copy.execute(context=context)
  File "/Users/arpitasaha/opt/anaconda3/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 113, in execute
    return_value = self.execute_callable()
  File "/Users/arpitasaha/opt/anaconda3/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 118, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/Users/arpitasaha/airflow/dags/tutorial.py", line 144, in getdf
    df = h.get_pandas_df("SELECT A.DocumentNo, A.FullName, A.Device, A.Country, B.OrderId, B.DocumentNo, B.OrderDate, B.CatalogId,C.CatalogId, C.ProductId, C.CUID, D.ProductId, D.ProductName, D.CUID FROM CUSTOMERS as A inner join ORDERS as B on A.DocumentNo = B.DocumentNo inner join CATALOG as C on C.CatalogId = B.CatalogId inner join PRODUCTS AS D ON C.CUID = D.CUID")
  File "/Users/arpitasaha/opt/anaconda3/lib/python3.7/site-packages/airflow/hooks/dbapi_hook.py", line 99, in get_pandas_df
    with closing(self.get_conn()) as conn:
  File "/Users/arpitasaha/opt/anaconda3/lib/python3.7/site-packages/airflow/hooks/sqlite_hook.py", line 40, in get_conn
    conn = sqlite3.connect(conn.host)
sqlite3.OperationalError: unable to open database file
[2020-10-19 22:11:04,499] {taskinstance.py:1194} INFO - Marking task as UP_FOR_RETRY. dag_id=tutorial, task_id=sqlite_to_df, execution_date=20201019T163015, start_date=20201019T164104, end_date=20201019T164104
[2020-10-19 22:11:09,413] {local_task_job.py:102} INFO - Task exited with return code 1
